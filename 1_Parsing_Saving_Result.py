# Когда мы парсим данные с различных веб-страниц, мы часто получаем сырые данные, которые неудобно (или вообще нельзя) использовать и которые нуждаются в обработке.
# В обработку входят:
# очистка данных — удаление лишних пробелов, специальных символов, лишней информации, исправление некорректных, повреждённых данных и т.д. Когда мы регулируем парсинг, лишней информации может почти не быть;
# преобразование данных — перевод строк в числа и т.п.;
# фильтрация данных — отбор только нужный случай


import requests

from bs4 import BeautifulSoup

url = 'https://www.python.org'

response = requests.get(url)

soup = BeautifulSoup(response.text, 'html.parser')

rows = soup.find_all('tr')
data = []
for row in rows:
    cols = row.find_all('td')
    cleaned_cols = [col.text.strip() for col in cols] # удаление лишних пробелов () если в скобки поставить символ то удалится символ
